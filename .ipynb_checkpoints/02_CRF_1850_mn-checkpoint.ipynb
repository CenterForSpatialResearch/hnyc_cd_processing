{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-crfsuite in /Users/geraldlee/opt/anaconda3/lib/python3.7/site-packages (0.3.6)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /Users/geraldlee/opt/anaconda3/lib/python3.7/site-packages (from sklearn-crfsuite) (0.9.7)\n",
      "Requirement already satisfied: six in /Users/geraldlee/opt/anaconda3/lib/python3.7/site-packages (from sklearn-crfsuite) (1.14.0)\n",
      "Requirement already satisfied: tabulate in /Users/geraldlee/opt/anaconda3/lib/python3.7/site-packages (from sklearn-crfsuite) (0.8.7)\n",
      "Requirement already satisfied: tqdm>=2.0 in /Users/geraldlee/opt/anaconda3/lib/python3.7/site-packages (from sklearn-crfsuite) (4.42.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training and test data\n",
    "def prepare_data(path):\n",
    "  df = pd.read_csv(path, engine = \"python\")\n",
    "  sents = []\n",
    "  record = []\n",
    "  cur = df['number'][0]\n",
    "  for index,row in df.iterrows():\n",
    "    if row['number'] != cur:\n",
    "      sents.append(record)\n",
    "      record = [(row['pos'], row['tag'])]\n",
    "    else:\n",
    "      record.append((row['pos'], row['tag']))\n",
    "    cur = row['number']\n",
    "  sents.append(record)\n",
    "\n",
    "  return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1880_train.csv                  final_output.json\r\n",
      "1880_validation.csv             final_output.pkl\r\n",
      "CRF.ipynb                       prediction.pkl\r\n",
      "City_Directory_Formatting.ipynb result.json\r\n",
      "Final_Output.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"input/1880\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = prepare_data(\"input/1880/1880_train.csv\")\n",
    "validation_sents = prepare_data(\"input/1880/1880_validation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show an example of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('START', 'START'),\n",
       " ('Otersen', 'NC'),\n",
       " ('Casten', 'NC'),\n",
       " (',', 'D'),\n",
       " ('produce', 'OC'),\n",
       " (',', 'D'),\n",
       " ('h', 'PA'),\n",
       " ('149', 'AC'),\n",
       " ('Franklin', 'AC'),\n",
       " ('END', 'END')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CRF features\n",
    "\n",
    "Feature Explanation\n",
    "\n",
    "is_junior_token: does it equal \"jr\"?\n",
    "\n",
    "is_widow_token: does it equal \"widow\"?\n",
    "\n",
    "contains_digit: does it contain any number?\n",
    "\n",
    "is_delimiter: is it a delimiter?\n",
    "\n",
    "is_start: start of record?\n",
    "\n",
    "is_end: end of record?\n",
    "\n",
    "is_lower: all lowercase letters?\n",
    "\n",
    "is_upper: all uppercase letters?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_junior_token(input):\n",
    "        dc = input.lower()\n",
    "        if dc == \"jr\":\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "def is_widow_token(input):\n",
    "        dc = input.lower()\n",
    "        if dc == \"wid\" or dc == \"widow\":\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "def contains_digit(input):\n",
    "        for c in input:\n",
    "            if c.isdigit():\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "def is_delimiter(input):\n",
    "        for c in input:\n",
    "            if c == '.' or c == ',':\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "def is_start(input):\n",
    "        if input == \"START\":\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "def is_end(input):\n",
    "        if input == \"END\":\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice that features are not only generated on the current word, but also previous and next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'is_junior_token': is_junior_token(word),\n",
    "        'is_widow_token': is_widow_token(word),\n",
    "        'contains_digit': contains_digit(word),\n",
    "        'is_delimiter': is_delimiter(word),\n",
    "        'is_start': is_start(word),\n",
    "        'is_end': is_end(word),\n",
    "        'is_lower': word.islower(),\n",
    "        'is_title': word.istitle(),\n",
    "        'is_upper': word.isupper(),\n",
    "        'substr[-2:]': word[-2:],\n",
    "        'substr[-1:]': word[-1:]\n",
    "    }\n",
    "\n",
    "    if i == 0:\n",
    "      features.update({'BOS':True})\n",
    "    elif i == len(sent) - 1:\n",
    "      features.update({'EOS':True})\n",
    "    else:\n",
    "      word_prev = sent[i-1][0]\n",
    "      word_next = sent[i+1][0]\n",
    "      features.update({'prev_is_lower': word_prev.islower(), \n",
    "                       'prev_is_title': word_prev.istitle(),\n",
    "                       'prev_is_upper': word_prev.isupper(),\n",
    "                       'prev_is_delimiter': is_delimiter(word_prev),\n",
    "                       'next_is_lower': word_next.islower(),\n",
    "                       'next_is_title': word_next.istitle(),\n",
    "                       'next_is_upper': word_next.isupper(),\n",
    "                       'next_contains_digit': contains_digit(word_next),\n",
    "                       'next_is_end': is_end(word_next)})\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for word, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from data\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "X_validation = [sent2features(s) for s in validation_sents]\n",
    "y_validation = [sent2labels(s) for s in validation_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geraldlee/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=500,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=500,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Precision, recall and f1-score are used as evaluation metrics.\n",
    "\n",
    "A detailed explanation on metrics: https://medium.com/analytics-vidhya/pos-tagging-using-conditional-random-fields-92077e5eaa31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9906933631825323"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "y_pred = crf.predict(X_validation)\n",
    "metrics.flat_f1_score(y_validation, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice that evaluation metrics are applied to each category (AC, NC, PA etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           D      1.000     0.963     0.981        54\n",
      "          PA      1.000     1.000     1.000        21\n",
      "          AC      0.989     1.000     0.995        94\n",
      "          NC      0.975     1.000     0.988        79\n",
      "          OC      1.000     0.955     0.977        22\n",
      "         END      1.000     1.000     1.000        27\n",
      "       START      1.000     1.000     1.000        27\n",
      "\n",
      "    accuracy                          0.991       324\n",
      "   macro avg      0.995     0.988     0.991       324\n",
      "weighted avg      0.991     0.991     0.991       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metrics by label\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_validation, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply model to the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "file_path = \"input/1850/nypl_1850_51_starred_clean.txt\"\n",
    "\n",
    "with open(file_path) as f:\n",
    "  data = f.readlines()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format record to apply model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted = []\n",
    "for record in data:\n",
    "  ls = record.split()\n",
    "  if ls:\n",
    "    if bool(re.match(\"([A-Z]+\\.)\", ls[0])) == True:\n",
    "      continue\n",
    "    else:\n",
    "      record_split = []\n",
    "      for word in ls[1:]:\n",
    "        if word[-1] == \".\" or word[-1] == \",\":\n",
    "          record_split.append(word[:-1])\n",
    "          record_split.append(word[-1])\n",
    "        else:\n",
    "          record_split.append(word)\n",
    "    formatted.append([ls[0], record_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(s):\n",
    "  sents = [[(word,0) for word in s]]\n",
    "  sents[0].insert(0, ('START',0))\n",
    "  sents[0].append(('END', 0))\n",
    "  X = [sent2features(s) for s in sents]\n",
    "  y = crf.predict(X)\n",
    "  return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(formatted)\n",
    "for i in range(n):\n",
    "  labels = predict_label(formatted[i][1])\n",
    "  formatted[i].append(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the list to save preliminary result\n",
    "with open(\"input/1850/prediction.pkl\", \"wb\") as f:\n",
    "  pickle.dump(formatted,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Prediction into JSON format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve result\n",
    "with open(\"input/1850/prediction.pkl\", 'rb') as f:\n",
    "  d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for record in d:\n",
    "  d_record = {}\n",
    "  d_record[\"index\"] = int(record[0])\n",
    "  n = len(record[1])\n",
    "  start = 1\n",
    "  for i in range(1, n + 1):\n",
    "    if i <  n:\n",
    "      # Skip delimiters\n",
    "      if record[2][i] == \"D\":\n",
    "        start = i+1\n",
    "        continue\n",
    "      elif record[2][i+1] == \"D\":\n",
    "        try:\n",
    "          d_record[record[2][i]].append(record[1][(start-1):i])\n",
    "        except:\n",
    "          d_record[record[2][i]] = [record[1][(start-1):i]]\n",
    "        start = i + 2\n",
    "    else:\n",
    "      try:\n",
    "          d_record[record[2][i]].append(record[1][(start-1):])\n",
    "      except:\n",
    "          d_record[record[2][i]] = [record[1][(start-1):]]\n",
    "\n",
    "  output.append(d_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate primary fields\n",
    "\n",
    "Here 4 primary fields are generated to faciliate the generation of final output: Occupation, Name, Marriage_Status and Address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = {}\n",
    "for record in output:\n",
    "  new = {}\n",
    "  try:\n",
    "    occupation = record['OC']\n",
    "    new['Occupation'] = []\n",
    "    for oc in occupation:\n",
    "      new['Occupation'].append(' '.join(oc))\n",
    "    new['Occupation'] = ' '.join(new['Occupation'])\n",
    "  except:\n",
    "    pass\n",
    "  try:\n",
    "    # Deal with widow marriage status\n",
    "    name = record['NC']\n",
    "    new['Name'] = ' '.join(name[0])\n",
    "    if len(name) > 1:\n",
    "      if name[1][0] == 'widow':\n",
    "        new['Marriage_Status'] = 'widow'\n",
    "      else:\n",
    "        new['Marriage_Status'] = 'widow of ' + ' '.join(name[1][2:])\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  try:\n",
    "    # Multiple address\n",
    "    address = record['AC']\n",
    "    if len(address) == 1:\n",
    "      if address[0][0] == \"h\":\n",
    "        new['Address'] = [['h', ' '.join(address[0][1:])]]\n",
    "      else:\n",
    "        new['Address'] = [['assume_h', ' '.join(address[0])]]\n",
    "    else:\n",
    "      new['Address'] = []\n",
    "      for ad in address:\n",
    "        if ad[0] == \"h\":\n",
    "          new['Address'].append(['h', ' '.join(ad[1:])])\n",
    "        else:\n",
    "          new['Address'].append(['w', ' '.join(ad)])\n",
    "  except:\n",
    "    pass\n",
    "  \n",
    "  final[str(record['index'])] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file\n",
    "with open('input/1850/result.json', 'w') as f:\n",
    "    json.dump(final,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file\n",
    "with open('input/1850/result.json', 'r') as f:\n",
    "    d = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Occupation': 'conductor',\n",
       " 'Name': 'Banta Peter',\n",
       " 'Address': [['h', '. E . 31st n . Av . 4']]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['1570']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bogart Peter L . imp . 34 Broadway , & grocer , 162 E . Broadway , h . Eighth b . Av . A . & Av . 1\n",
      "{'Occupation': 'imp & grocer', 'Name': 'Bogart Peter L', 'Address': [['w', '34 Broadway'], ['w', '162 E . Broadway'], ['h', '. Eighth b . Av . A . & Av . 1']]}\n",
      "\n",
      "\n",
      "Bogart Peter S . carman , 11 Leroy\n",
      "{'Occupation': 'carman', 'Name': 'Bogart Peter S', 'Address': [['assume_h', '11 Leroy']]}\n",
      "\n",
      "\n",
      "Bogart Rachel , 149 Varick\n",
      "{'Name': 'Bogart Rachel', 'Address': [['assume_h', '149 Varick']]}\n",
      "\n",
      "\n",
      "Bogart Sarah W . boarding , 335 Pearl\n",
      "{'Occupation': 'boarding', 'Name': 'Bogart Sarah W', 'Address': [['assume_h', '335 Pearl']]}\n",
      "\n",
      "\n",
      "Bogart Steph , lmbr , Av . 10 c . W . 15th , h . 78 W . 21st\n",
      "{'Occupation': 'lmbr', 'Name': 'Bogart Steph', 'Address': [['w', 'Av . 10 c . W . 15th'], ['h', '. 78 W . 21st']]}\n",
      "\n",
      "\n",
      "Bogart Timothy , builder , r . 209.5 Wooster , h . 137 Amity\n",
      "{'Occupation': 'builder r', 'Name': 'Bogart Timothy', 'Address': [['w', '209.5 Wooster'], ['h', '. 137 Amity']]}\n",
      "\n",
      "\n",
      "Bogel Orville N . butcher , 183 Av . 3\n",
      "{'Occupation': 'butcher', 'Name': 'Bogel Orville N', 'Address': [['assume_h', '183 Av . 3']]}\n",
      "\n",
      "\n",
      "Bogereau Joseph , — E . Broadway\n",
      "{'Name': 'Bogereau Joseph', 'Address': [['assume_h', '— E . Broadway']]}\n",
      "\n",
      "\n",
      "Bogert Abraham L . tobacco , 56 Vesey , h . 15 Atlan- tic , Brooklyn\n",
      "{'Occupation': 'tobacco', 'Name': 'Bogert Abraham L', 'Address': [['w', '56 Vesey'], ['h', '. 15 Atlan- tic , Brooklyn']]}\n",
      "\n",
      "\n",
      "Bogert Albert , jr . clerk , h . 9 Cornelia\n",
      "{'Occupation': 'jr clerk', 'Name': 'Bogert Albert', 'Address': [['h', '. 9 Cornelia']]}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10 alphabetical examples\n",
    "for i in range(3100, 3110):\n",
    "  print(' '.join(formatted[i-1][1]))\n",
    "  print(final[str(i)])\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
